{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/melody/Documents/Courses 2021 spring/ling_programming/term project',\n",
       " '/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python39.zip',\n",
       " '/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9',\n",
       " '/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/melody/Library/Python/3.9/lib/python/site-packages',\n",
       " '/usr/local/lib/python3.9/site-packages',\n",
       " '/usr/local/lib/python3.9/site-packages/IPython/extensions',\n",
       " '/Users/melody/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/melody/Documents/Courses 2021 spring/ling_programming/term project',\n",
       " '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python38.zip',\n",
       " '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8',\n",
       " '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/Users/melody/Documents/Courses 2021 spring/ling_programming/term project/pdf_ocr/lib/python3.8/site-packages',\n",
       " '/Users/melody/Documents/Courses 2021 spring/ling_programming/term project/pdf_ocr/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/Users/melody/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install other dependencies:\n",
    "- [tesseract](https://github.com/tesseract-ocr/tesseract/releases)\n",
    "    - Mac: brew install tesseract \n",
    "- poppler\n",
    "    - Windoes: download [here](), install, add to PATH\n",
    "    - Mac: brew install poppler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem with importing cv2\n",
    "- check if juyter is installed in virtual env\n",
    "- check if \n",
    "```\n",
    "import sys\n",
    "sys.path\n",
    "```\n",
    "in both jupyter notebook andn in terminal have the same path\n",
    "\n",
    "- if error message is ```ImportError: libGL.so.1: cannot open shared object file: No such file or directory```:  \n",
    "do in terminal:\n",
    "```\n",
    "sudo apt update\n",
    "sudo apt install libgl1-mesa-glx\n",
    "```\n",
    "source: https://github.com/conda-forge/pygridgen-feedstock/issues/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#from pytesser.pytesser import *\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "from pdf2image.exceptions import (\n",
    "    PDFInfoNotInstalledError,\n",
    "    PDFPageCountError,\n",
    "    PDFSyntaxError\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poppler resources:\n",
    "https://github.com/Belval/pdf2image/issues/101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.PpmImagePlugin.PpmImageFile'>\n"
     ]
    }
   ],
   "source": [
    "# convert pdf to images\n",
    "# v useful tutorial: https://www.geeksforgeeks.org/convert-pdf-to-image-using-python/\n",
    "\n",
    "images = convert_from_path('sample-papers/assym.pdf', dpi=100, first_page=1, last_page=1)\n",
    "print(type(images[0]))\n",
    "# for i in range(len(images)):\n",
    "#     images[i].save('page'+ str(i) +'.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].save('page_1.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do it with gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you can even do it with a gui!!\n",
    "# package needed: tkinter\n",
    "\n",
    "# from pdf2image import convert_from_path\n",
    "# from tkinter import *\n",
    "# from tkinter import messagebox\n",
    " \n",
    "# def pdf2img():\n",
    "#     try:\n",
    "#         images = convert_from_path(str(e1.get()))\n",
    "#         for img in images:\n",
    "#             img.save('new_folder\\output.jpg', 'JPEG')\n",
    " \n",
    "#     except  :\n",
    "#         Result = \"NO pdf found\"\n",
    "#         messagebox.showinfo(\"Result\", Result)\n",
    " \n",
    "#     else:\n",
    "#         Result = \"success\"\n",
    "#         messagebox.showinfo(\"Result\", Result)\n",
    " \n",
    "\n",
    "# master = Tk()\n",
    "# Label(master, text=\"File Location\").grid(row=0, sticky=W)\n",
    " \n",
    "# e1 = Entry(master)\n",
    "# e1.grid(row=0, column=1)\n",
    " \n",
    "# b = Button(master, text=\"Convert\", command=pdf2img)\n",
    "# b.grid(row=0, column=2,columnspan=2, rowspan=2,padx=5, pady=5)\n",
    "  \n",
    "# mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "img1 = np.array(Image.open('page_1.jpg'))\n",
    "text = pytesseract.image_to_string(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "with tesserocr.PyTessBaseAPI() as api:\n",
    "    #image = Image.open(io.BytesIO(req_image))\n",
    "    api.SetImage(Image.open('skr.png'))\n",
    "    api.Recognize()  # required to get result from the next line\n",
    "    iterator = api.GetIterator()\n",
    "    print(iterator.WordFontAttributes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'method_descriptor' object has no attribute 'getattr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-295a3659ea01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesserocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTessBaseAPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetIterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'method_descriptor' object has no attribute 'getattr'"
     ]
    }
   ],
   "source": [
    "print(tesserocr.PyTessBaseAPI.GetIterator.getattr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__new__: <built-in method __new__ of type object at 0x13805bfa0>\n",
      "Version: <staticmethod object at 0x1378949d0>\n",
      "ClearPersistentCache: <staticmethod object at 0x137971eb0>\n",
      "GetDatapath: <method 'GetDatapath' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetOutputName: <method 'SetOutputName' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetVariable: <method 'SetVariable' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetDebugVariable: <method 'SetDebugVariable' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetIntVariable: <method 'GetIntVariable' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetBoolVariable: <method 'GetBoolVariable' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetDoubleVariable: <method 'GetDoubleVariable' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetStringVariable: <method 'GetStringVariable' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetVariableAsString: <method 'GetVariableAsString' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "InitFull: <method 'InitFull' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "Init: <method 'Init' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetInitLanguagesAsString: <method 'GetInitLanguagesAsString' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetLoadedLanguages: <method 'GetLoadedLanguages' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetAvailableLanguages: <method 'GetAvailableLanguages' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "InitForAnalysePage: <method 'InitForAnalysePage' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "ReadConfigFile: <method 'ReadConfigFile' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetPageSegMode: <method 'SetPageSegMode' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetPageSegMode: <method 'GetPageSegMode' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "TesseractRect: <method 'TesseractRect' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "ClearAdaptiveClassifier: <method 'ClearAdaptiveClassifier' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetImageBytes: <method 'SetImageBytes' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetImage: <method 'SetImage' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetImageFile: <method 'SetImageFile' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetSourceResolution: <method 'SetSourceResolution' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "SetRectangle: <method 'SetRectangle' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetThresholdedImage: <method 'GetThresholdedImage' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetRegions: <method 'GetRegions' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetTextlines: <method 'GetTextlines' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetStrips: <method 'GetStrips' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetWords: <method 'GetWords' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetConnectedComponents: <method 'GetConnectedComponents' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetComponentImages: <method 'GetComponentImages' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetThresholdedImageScaleFactor: <method 'GetThresholdedImageScaleFactor' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "AnalyseLayout: <method 'AnalyseLayout' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "Recognize: <method 'Recognize' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "RecognizeForChopTest: <method 'RecognizeForChopTest' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "ProcessPages: <method 'ProcessPages' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "ProcessPage: <method 'ProcessPage' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetIterator: <method 'GetIterator' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetUTF8Text: <method 'GetUTF8Text' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetBestLSTMSymbolChoices: <method 'GetBestLSTMSymbolChoices' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetHOCRText: <method 'GetHOCRText' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetTSVText: <method 'GetTSVText' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetBoxText: <method 'GetBoxText' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetUNLVText: <method 'GetUNLVText' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "DetectOrientationScript: <method 'DetectOrientationScript' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "MeanTextConf: <method 'MeanTextConf' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "AllWordConfidences: <method 'AllWordConfidences' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "AllWords: <method 'AllWords' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "MapWordConfidences: <method 'MapWordConfidences' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "AdaptToWordStr: <method 'AdaptToWordStr' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "Clear: <method 'Clear' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "End: <method 'End' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "IsValidCharacter: <method 'IsValidCharacter' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetTextDirection: <method 'GetTextDirection' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "DetectOS: <method 'DetectOS' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "GetUnichar: <method 'GetUnichar' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "oem: <method 'oem' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "set_min_orientation_margin: <method 'set_min_orientation_margin' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "__enter__: <method '__enter__' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "__exit__: <method '__exit__' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "__doc__: Cython wrapper class around the C++ TessBaseAPI class.\n",
      "\n",
      "    Usage as a context manager:\n",
      "\n",
      "    >>> with PyTessBaseAPI(path='./', lang='eng') as tesseract:\n",
      "    ...     tesseract.SetImage(image)\n",
      "    ...     text = tesseract.GetUTF8Text()\n",
      "\n",
      "    Example with manual handling:\n",
      "\n",
      "    >>> tesseract = PyTessBaseAPI(path='./', lang='eng')\n",
      "    >>> try:\n",
      "    ...     tesseract.SetImage(image)\n",
      "    ...     text = tesseract.GetUTF8Text()\n",
      "    ... finally:\n",
      "    ...     tesseract.End()\n",
      "\n",
      "    Args:\n",
      "        path (str): The name of the parent directory of tessdata.\n",
      "            Must end in /.\n",
      "        lang (str): An ISO 639-3 language string. Defaults to 'eng'.\n",
      "            The language may be a string of the form [~]<lang>[+[~]<lang>]* indicating\n",
      "            that multiple languages are to be loaded. Eg hin+eng will load Hindi and\n",
      "            English. Languages may specify internally that they want to be loaded\n",
      "            with one or more other languages, so the ~ sign is available to override\n",
      "            that. Eg if hin were set to load eng by default, then hin+~eng would force\n",
      "            loading only hin. The number of loaded languages is limited only by\n",
      "            memory, with the caveat that loading additional languages will impact\n",
      "            both speed and accuracy, as there is more work to do to decide on the\n",
      "            applicable language, and there is more chance of hallucinating incorrect\n",
      "            words.\n",
      "        psm (int): Page segmentation mode. Defaults to :attr:`PSM.AUTO`.\n",
      "            See :class:`PSM` for available psm values.\n",
      "        init (bool): If ``False``, :meth:`Init` will not be called and has to be called\n",
      "            after initialization.\n",
      "        oem (int): OCR engine mode. Defaults to :attr:`OEM.DEFAULT`.\n",
      "\n",
      "    Raises:\n",
      "        :exc:`RuntimeError`: If `init` is ``True`` and API initialization fails.\n",
      "    \n",
      "__pyx_vtable__: <capsule object NULL at 0x10fed4b10>\n",
      "__reduce__: <method '__reduce_cython__' of 'tesserocr.PyTessBaseAPI' objects>\n",
      "__setstate__: <method '__setstate_cython__' of 'tesserocr.PyTessBaseAPI' objects>\n"
     ]
    }
   ],
   "source": [
    "for k, v in tesserocr.PyTessBaseAPI.__dict__.items():\n",
    "    print(\"{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-55-6e708f1ec280>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-6e708f1ec280>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print({k:v for k:v in tesserocr.PyTessBaseAPI.__dict__})\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print({k:v for k:v in tesserocr.PyTessBaseAPI.__dict__})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleSpec(name='tesserocr', loader=<_frozen_importlib_external.ExtensionFileLoader object at 0x137916100>, origin='/Users/melody/Documents/Courses 2021 spring/ling_programming/term project/pdf_ocr/lib/python3.8/site-packages/tesserocr.cpython-38-darwin.so')\n"
     ]
    }
   ],
   "source": [
    "print(tesserocr.__spec__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As schema.org has grown, we have explored various mechanisms for community extension as a way of adding\n",
      "more detailed descriptive vocabulary that builds on the schema.org core. Some areas of Schema.org were\n",
      "developed as \"named extensions\", and have dedicated entry pages. We previously called these \"hosted\"\n",
      "extensions, but they are best considered simply as views into a single collection of schema definitions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tesserocr.image_to_text(Image.open('skr.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? frontiers\n",
      "in Psychology\n",
      "\n",
      " \n",
      "\n",
      "RESEARCH\n",
      "\n",
      "   \n",
      "\n",
      " \n",
      "\n",
      "OPEN ACCESS\n",
      "\n",
      "Exlited by:\n",
      "ifana Progovac,\n",
      "Wayne State University, United States\n",
      "\n",
      " \n",
      "\n",
      "Unversity of Graz, Aust\n",
      "“Correspondence:\n",
      "and Gi\n",
      "\n",
      "@sthimeg ae\n",
      "\n",
      "Speciaty section:\n",
      "Tarte was submited to\n",
      "Language Sciences,\n",
      "\n",
      "the journal\n",
      "\n",
      "Frontors in Psychaloay\n",
      "\n",
      "  \n",
      "\n",
      "Received: 25.48 2019,\n",
      "Accepted: 23 Septzmber 2019\n",
      "Published: 17 October 2019\n",
      "Citation:\n",
      "\n",
      "GD anc Shan ¥ 2019) How\n",
      "(Grammar introduces Asymmaty Into\n",
      "Cognitive Stuctures: Compostional\n",
      "‘Semantics, Metaphor,\n",
      "\n",
      "and\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract title only by splitting string by the first single line cintaining only \\n\n",
    "# since titles are often the first few lines in a document and are separated from the rest of the test\n",
    "# with a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vy 2021', '', '06912v1 [cs.CL] 14M', '', '5:', '', 'arXiv:210.', '', 'a', '', ' ', '', 'QAConv: Question Answering on Informative', 'Conversations', '', ' ', '', \"Chien-Sheng Wu', Andrea Madotto', Wenhao Liu', Pascale Fung’, Caiming Xiong!\", '‘Salesforce Al Research', '', '+The Hong Kong University of Sci', '', '{wu. jason, venhao.liu, cxiong}@salesforce.com anadotto@connect .ust.hk', '', ' ', '', 'Abstract.', '', '‘This paper introduces QACom{|] a new question answering (QA) dataset that uses', 'conversations as a knowledge source. We focus on informative conversations', 'including business emails, panel discussions, and work channels. Unlike open-', 'domain and task-oriented dialogues, these conversations are usually long, complex,', 'asynchronous, and involve strong domain knowledge. In total, we collect 34,204', 'QA pairs, including span-based, free-form, and unanswerable questions, from', '10,259 selected conversations with both human-written and machine-generated', 'questions. We segment long conversations into chunks, and use a question gen-', 'erator and dialogue summarizer as auxiliary tools to collect multi-hop questions.', '‘The dataset has two testing scenarios, chunk mode and full mode, depending on', 'whether the grounded chunk is provided or retrieved from a large conversational', 'pool. Experimental results show that state-of-the-art QA systems trained on exist-', 'ing QA datasets have limited zero-shot ability and tend to predict our questions', 'as unanswerable, Fine-tuning such systems on our corpus can achieve signifi-', 'cant improvement up to 23.6% and 13.6% in both chunk mode and full mode,', 'respectively', '', ' ', '', ' ', '', ' ']\n"
     ]
    }
   ],
   "source": [
    "splt_txt = text.split('\\n')\n",
    "print(splt_txt[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lightweight, Dynamic Graph Convolutional Networks', 'for AMR-to-Text Generation']\n"
     ]
    }
   ],
   "source": [
    "splt_text = text.split('\\n')\n",
    "\n",
    "title = []\n",
    "for line in splt_text:\n",
    "    if line == '':\n",
    "        title = splt_text[:splt_text.index(line)]\n",
    "        break\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image processing, prob not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reduce noise in image\n",
    "# normalization, thresholding and image blur\n",
    "norm_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "img = cv2.normalize(img, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "img = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "img = cv2.GaussianBlur(img, (1, 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((2, 1), np.uint8)\n",
    "img = cv2.erode(grey, kernel, iterations=1)\n",
    "img = cv2.dilate(img, kernel, iterations=1)\n",
    "out_below = pytesseract.image_to_string(img)\n",
    "print(\"OUTPUT:\", out_below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import image\n",
    "path_ = ''\n",
    "img = cv2.read(path_)\n",
    "grey = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "grey, img_bin = cv2.threshold(grey, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "grey = cv2.bitwise_not(img_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paper info from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
